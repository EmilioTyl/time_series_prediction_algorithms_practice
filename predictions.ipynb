{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Tesla's stock prices based on different predictions algorithms\n",
    "\n",
    "This practice is inspired by the challange presented in https://www.youtube.com/watch?v=JuLCL3wCEAk by Siraj Raval \n",
    "and \"Hands on Machine Learning with Scikit-Learn and Tensorflow\" by Aurelien Geron\n",
    "\n",
    "The main idea is to train a different machine learning models on Tesla stock's historical data as well as the sentiment from news headlines and other data sources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import unicodedata\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Headlines Sentiment Analysis of NY Time's headlines about Tesla\n",
    "df = pd.read_pickle('./data/TSLA_stock_information.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df,pd.DataFrame(columns=['compund','neg', 'neu','pos'])])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "for day in df.index:\n",
    "    sentiment = None\n",
    "    headlines = df.loc[day,'headlines'].split('/_/')\n",
    "    for headline in headlines\n",
    "        headline = unicodedata.normalize('NFKD', headline).encode('ascii','ignore')\n",
    "        new_sentiment = sentiment_analyzer.polarity_scores(sentence)\n",
    "        if sentiment is None:\n",
    "            sentiment = new_sentiment\n",
    "        else:\n",
    "             sentiment = { sentiment[key] + new_sentiment[key] for key in sentiment.keys()}\n",
    "    qty = len(headlines)\n",
    "    for key in sentiment.keys()\n",
    "        df.set_value(day, key, sentiment[key]/qty)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('headlines', axis=1, inplace=True)\n",
    "#df['close'] = df['close'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('./data/TSLA_sentiment_information_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splits sets\n",
    "\n",
    "def add_lastday_label(X, y):\n",
    "    X_size = X.size\n",
    "    new_set = np.zeros(X_size[0],X_size[1] +1)\n",
    "    new_set[:, :-1] = X\n",
    "    new_set[1:, -1] = y[:,:-1]\n",
    "    return new_set[1:, :]\n",
    "\n",
    "def split(dates, df, X_attr, y_attr):\n",
    "    splits = []\n",
    "    for start_date, end_date in dates:\n",
    "        parcial_df = df.ix[start_date : end_date]\n",
    "        X_set = parcial_df.as_matrix(columns = X_attr)\n",
    "        y_set = parcial_df.as_matrix(columns = y_attr)\n",
    "        splits.append([X_set, y_set])\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "'''\n",
    "train = df.ix[train_start_date : train_end_date]\n",
    "val = df.ix[val_start_date : val_end_date]\n",
    "test = df.ix[test_start_date:test_end_date]\n",
    "\n",
    "X_train = train.as_matrix(columns=['neg', 'neu','pos'])\n",
    "y_train = train.as_matrix(columns=['close'])\n",
    "\n",
    "X_val = val.as_matrix(columns=['neg', 'neu','pos'])\n",
    "y_val = val.as_matrix(columns=['close'])\n",
    "\n",
    "X_test = test.as_matrix(columns=['neg', 'neu','pos'])\n",
    "y_test = test.as_matrix(columns=['close'])\n",
    "\n",
    "#adding last day close\n",
    "X_train = add_lastday_price(X_train)\n",
    "X_test = add_lastday_price(X_test)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## First Approach, test differents models with default hiperparameters in order to identy the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## First Model: Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train_start_date = '20100629'\n",
    "train_end_date = '20150629'\n",
    "\n",
    "#val_start_date = '20150629'\n",
    "#val_end_date = '20160629'\n",
    "\n",
    "test_start_date = '20160630'\n",
    "test_end_date = '20170911'\n",
    "\n",
    "split_set = split([[train_start_date, train_end_date], [test_start_date,test_end_date]],\n",
    "                  df, ['neg', 'neu','pos'], ['close'] )\n",
    "\n",
    "X_train, y_train = split[0]\n",
    "X_test, y_test = split[1]\n",
    "\n",
    "X_train = add_lastday_price(X_train)\n",
    "X_test = add_lastday_price(X_test)\n",
    "\n",
    "# Random forest without parametrizing -> risk of overfitting\n",
    "\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "random_forest.fit(X_tarin, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Gradient Boost regressson with early stopping -> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df_pred = pd.DataFrame(data=y_pred[0:], index = pd.date_range(test_start_date, test_end_date), columns=['predicted_close_price'])\n",
    "df_y_test = df.ix[test_start_date:test_end_date]['close']\n",
    "df_y_test.rename(columns={'close': 'actual_close_price'})\n",
    "\n",
    "\n",
    "def plot_stock_dataframes(predictions_df, df_y_test):\n",
    "    df_pred_plot = predictions_df.plot()\n",
    "    df_pred_plot.set_xlabel('Dates')\n",
    "    df_pred_plot.set_ylabel('Close Prices')\n",
    "    fig = df_y_test.plot(ax = df_pred_plot).get_figure()\n",
    "    \n",
    "plot_stock_dataframes(predictions_df, df_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Second Model: Regresor NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Third Model: Recurrent NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fourth Modek: DeepMind's WaveNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
